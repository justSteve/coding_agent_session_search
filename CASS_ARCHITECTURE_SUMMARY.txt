╔════════════════════════════════════════════════════════════════════════════╗
║         CASS (CODING AGENT SESSION SEARCH) - FAST SEARCH PATTERNS          ║
╚════════════════════════════════════════════════════════════════════════════╝

SEARCH ARCHITECTURE LAYERS
───────────────────────────────────────────────────────────────────────────────

 ┌─────────────────────────────────────────────────────────────────────────┐
 │                         USER QUERY INPUT                                │
 └────────────────────────────┬────────────────────────────────────────────┘
                              │
                              ▼
 ┌─────────────────────────────────────────────────────────────────────────┐
 │                    QUERY PARSING & OPTIMIZATION                          │
 │  • Boolean operators (AND, OR, NOT)                                      │
 │  • Quoted phrase detection                                               │
 │  • Wildcard pattern analysis                                             │
 │  • Prefix-only detection (bypass snippet generation)                     │
 └────────────────────────────┬────────────────────────────────────────────┘
                              │
                    ┌─────────┴─────────┐
                    ▼                   ▼
        ┌─────────────────────┐  ┌─────────────────────┐
        │  CHECK PREFIX CACHE │  │ BUILD FILTER TERMS  │
        │  (LRU + Bloom64)    │  │ (Agent/Workspace)   │
        │  <5ms if hit        │  │                     │
        └──────────┬──────────┘  └──────────┬──────────┘
                   │                        │
              Cache miss                    │
              or shortfall                  │
                   │                        │
                   └────────────┬───────────┘
                                ▼
        ┌──────────────────────────────────────────────────────────┐
        │           TANTIVY FULL-TEXT SEARCH ENGINE                │
        │  ┌──────────────────────────────────────────────────────┐│
        │  │ Schema: INDEXED FIELDS                               ││
        │  │  • title, content (TEXT | STORED)                    ││
        │  │  • title_prefix, content_prefix (EDGE N-GRAMS)       ││
        │  │  • agent, workspace (STRING | exact match)           ││
        │  │  • created_at (I64 | range queries)                  ││
        │  │  • source_id, origin_kind (provenance)               ││
        │  └──────────────────────────────────────────────────────┘│
        │  ┌──────────────────────────────────────────────────────┐│
        │  │ Query Execution                                      ││
        │  │  1. Build BooleanQuery clauses                       ││
        │  │  2. Apply filter clauses (MUST)                      ││
        │  │  3. Execute searcher.search() with TopDocs           ││
        │  │  4. BM25 scoring                                     ││
        │  │  5. Snippet generation (or fast prefix snippet)      ││
        │  └──────────────────────────────────────────────────────┘│
        │  Speed: 5-100ms typical (up to 500ms for complex queries)│
        └──────────────────────────┬───────────────────────────────┘
                                   │
                                   ▼
        ┌──────────────────────────────────────────────────────────┐
        │           SEMANTIC SEARCH (Optional)                      │
        │  • FastEmbed embedder (MiniLM or hash-based fallback)    │
        │  • Vector index (CVVI format)                             │
        │  • F32 or F16 quantization                                │
        │  Speed: 100-1000ms (embedding inference)                  │
        └──────────────────────────┬───────────────────────────────┘
                                   │
            ┌──────────────────────┴──────────────────────┐
            ▼                                             ▼
    ┌─────────────────────┐                    ┌──────────────────┐
    │   LEXICAL RESULTS   │                    │ SEMANTIC RESULTS │
    │   (TopN docs)       │                    │ (TopN docs)      │
    └────────────┬────────┘                    └────────┬─────────┘
                 │                                     │
                 └──────────────────┬──────────────────┘
                                    ▼
    ┌──────────────────────────────────────────────────────────┐
    │  HYBRID MODE: RRF FUSION (Reciprocal Rank Fusion)        │
    │  • Fetch 3x candidates from each result set               │
    │  • Score = Σ(1 / (K + rank)) where K=60                  │
    │  • Documents in both sets get boosted                     │
    │  • Deterministic fusion (reproducible)                    │
    └──────────────────────────┬───────────────────────────────┘
                               │
                               ▼
    ┌──────────────────────────────────────────────────────────┐
    │           POST-SEARCH PROCESSING                          │
    │  • Session paths filter (not indexed, applied after)       │
    │  • Deduplication: (source_id, content) grouping            │
    │  • Tool noise filtering (regex check)                      │
    │  • Respects source boundaries (P2.3)                       │
    └──────────────────────────┬───────────────────────────────┘
                               │
                               ▼
    ┌──────────────────────────────────────────────────────────┐
    │              CACHE RESULT FOR REUSE                        │
    │  • CachedHit stores: hit + lowercase fields + bloom64      │
    │  • Bloom filter: 1 bit per token (fast gate)               │
    │  • LRU eviction when limits exceeded                       │
    │  • Next prefix query filters cached results                │
    └──────────────────────────┬───────────────────────────────┘
                               │
                               ▼
                    ┌──────────────────────┐
                    │  RETURN SEARCH HITS  │
                    │  (Ranked + Scored)   │
                    └──────────────────────┘


KEY OPTIMIZATION TECHNIQUES
───────────────────────────────────────────────────────────────────────────────

┌─ LAYER 1: PREFIX CACHE ─────────────────────────────────────────────────┐
│  • LRU cache with Bloom filter gates                                     │
│  • Reuses cached results while user types                               │
│  • Prevents false reuse via bloom gate + token verification             │
│  • Cache key includes query + filters + schema hash                     │
│  • Hit rate: 60-80% typical for interactive typing                      │
└─────────────────────────────────────────────────────────────────────────┘

┌─ LAYER 2: WARM WORKER ──────────────────────────────────────────────────┐
│  • Background tokio task for index reload                               │
│  • Debounced to 300ms interval (prevent thrashing)                      │
│  • Executes mini search (limit:1) to page in OS cache                   │
│  • Non-blocking: doesn't impact user input                              │
│  • Graceful fallback if no Tokio runtime (tests)                        │
└─────────────────────────────────────────────────────────────────────────┘

┌─ LAYER 3: SEGMENT MERGING ──────────────────────────────────────────────┐
│  • Threshold: 4+ searchable segments trigger merge                       │
│  • Cooldown: 5 minute minimum between merges                            │
│  • Asynchronous: runs in background                                     │
│  • Reduces per-query cost (fewer segments to search)                    │
│  • Automatic optimization without user intervention                     │
└─────────────────────────────────────────────────────────────────────────┘

┌─ LAYER 4: EDGE N-GRAMS ─────────────────────────────────────────────────┐
│  • Pre-computed n-grams for prefix matching                             │
│  • Example: "hello" → ["he", "hel", "hell", "hello"]                    │
│  • Stored in title_prefix + content_prefix fields                       │
│  • Avoids expensive regex for common prefix case                        │
│  • Fast term query instead of sequential scan                           │
└─────────────────────────────────────────────────────────────────────────┘

┌─ LAYER 5: SCHEMA VERSIONING ────────────────────────────────────────────┐
│  • SCHEMA_HASH = "tantivy-schema-v6-provenance-indexed"                 │
│  • Stored in schema_hash.json                                           │
│  • Mismatch triggers automatic rebuild                                  │
│  • Prevents subtle field-ID mismatches                                  │
│  • Current v6 includes provenance fields (P1.4)                         │
└─────────────────────────────────────────────────────────────────────────┘


PERFORMANCE CHARACTERISTICS
───────────────────────────────────────────────────────────────────────────────

Query Type                  Speed           Memory      Index Strategy
─────────────────────────────────────────────────────────────────────────────
Prefix (cached)            <5ms            Minimal     LRU Bloom gate
Prefix (uncached)          50-200ms        Index       Edge n-gram term
Term query                 5-50ms          Index       Tantivy inverted
Phrase query               20-100ms        Index       Position index
Wildcard prefix (*foo)     100-500ms       Index       RegexQuery scan
Boolean complex            50-500ms        Query       BooleanQuery nest
Time range filter          10-100ms        Index       RangeQuery
Full scan (empty query)    10-50ms         Index       AllQuery
Semantic search            100-1000ms      Vector      FastEmbed inference
Hybrid (RRF)               100-1500ms      Both        Dual execution


CORE TECHNOLOGIES
───────────────────────────────────────────────────────────────────────────────

Primary:     Tantivy (Rust full-text search engine)
             - Inverted index with BM25 scoring
             - Boolean query support
             - Field-specific indexing

Secondary:   Vector Index (Custom CVVI format)
             - FastEmbed for embeddings
             - F16 quantization support
             - Memory-mapped file access

Caching:     LRU cache + Bloom filters
             - Prefix result reuse
             - Token presence gates
             - Schema-aware key versioning

Async:       Tokio runtime
             - Multi-threaded task spawning
             - Warm worker background task
             - Debounced reload channel

Persistence: Tantivy (index) + SQLite (metadata)
             - Connection pooling
             - CRC32 checksums
             - SHA256 content hashing


FILTERING PIPELINE
───────────────────────────────────────────────────────────────────────────────

                            USER FILTERS
                                 │
                    ┌────────────┼────────────┐
                    │            │            │
              ┌─────▼────┐  ┌────▼─────┐  ┌──▼──────┐
              │  AGENTS  │  │WORKSPACE │  │TIME     │
              │(TermQry) │  │(TermQry) │  │(RangeQry)│
              └─────┬────┘  └────┬─────┘  └──┬──────┘
                    │            │           │
                    └────────────┼───────────┘
                                 │
                            ┌────▼────┐
                            │ SOURCE   │
                            │ FILTER   │
                            │(TermQry) │
                            └────┬─────┘
                                 │
                         Applied as MUST
                            clauses in
                         BooleanQuery
                                 │
                                 ▼
                        ┌─────────────────┐
                        │  TANTIVY EXEC   │
                        └────────┬────────┘
                                 │
                                 ▼
                     POST-SEARCH FILTERS
                     (session_paths,
                      deduplication,
                      noise filtering)
                                 │
                                 ▼
                          FILTERED RESULTS


MEMORY OPTIMIZATION
───────────────────────────────────────────────────────────────────────────────

Technique              Impact              Implementation
─────────────────────────────────────────────────────────────────────────────
F16 Quantization       50% reduction       half crate, memory-mapped vectors
Edge N-grams           +20-30% index       Pre-computed 2-to-len n-grams
Bloom Filter Gate      ~256 bits/entry     64-bit hash + token stream
Deduplication          Variable            HashMap<(source_id, content), score>
Streaming Results      Bounded memory      Offset-based pagination
LRU Cache Bounds       Configurable        Dual limit: entries + bytes


ARCHITECTURAL STRENGTHS
───────────────────────────────────────────────────────────────────────────────

✓ Deterministic:      Same query → same results (no randomness)
✓ Offline-first:      Lexical search works without external service
✓ Composable:         Lexical + semantic via RRF fusion
✓ Progressive:        Graceful degradation (hash embedder fallback)
✓ Auditable:          Provenance fields track result sources
✓ Responsive:         Multi-layer caching for interactive use
✓ Maintainable:       Clear separation (Tantivy/Vector/SQLite)
✓ Scalable:           Millions of documents, auto-merging segments
✓ Source-aware:       Boundary respect (P2.3) in deduplication


UNIQUE DESIGN DECISIONS
───────────────────────────────────────────────────────────────────────────────

1. CUSTOM CVVI FORMAT
   - Bespoke memory-mapped binary format vs external vector DB
   - Row-oriented (70 bytes/entry) for cache locality
   - Content-addressed dedup (SHA256)
   - Zero external dependencies for vector storage

2. PREFIX CACHE STRATEGY
   - Caches partial results instead of full result sets
   - Bloom filter gate prevents false reuse
   - Perfect for incremental typing (user types "hello" after "hel")
   - Smaller memory footprint than caching all matches

3. WARM WORKER ARCHITECTURE
   - Doesn't block user input (async background task)
   - Debounced to prevent OS cache thrashing
   - Runs tiny search to page in data before user sees latency
   - Graceful fallback when no Tokio runtime available

4. SOURCE BOUNDARY DEDUPLICATION
   - Same content from different sources → separate results
   - Maintains provenance clarity (P2.3)
   - Local vs remote sources appear distinctly
   - Prevents losing context from multi-source search

5. POST-SEARCH FILTERING
   - Session paths not indexed (too sparse)
   - Applied after Tantivy retrieval
   - Preserves index efficiency
   - Handles dynamic constraints (chained searches)

6. EDGE N-GRAM APPROACH
   - Pre-computed n-grams for prefix matching
   - Avoids regex overhead (expensive for every term)
   - Leverages fast Tantivy term matching
   - No sequential scanning needed


FILE STRUCTURE (Key modules)
───────────────────────────────────────────────────────────────────────────────

src/search/
  ├── query.rs           (→ 6583 lines)
  │   • SearchClient      - Main query API
  │   • search_tantivy()  - Lexical search execution
  │   • Prefix cache      - LRU + Bloom filter
  │   • RRF fusion        - Hybrid search ranking
  │   • Deduplication     - (source_id, content) grouping
  │   • Snippet generation - Context highlighting
  │
  ├── tantivy.rs
  │   • TantivyIndex      - Index creation/management
  │   • build_schema()    - Field definitions
  │   • ensure_tokenizer()- Custom analyzer setup
  │   • Merge optimization - Segment management
  │   • Edge n-gram generation
  │
  ├── vector_index.rs
  │   • VectorIndex       - CVVI format reader
  │   • CvviHeader        - Binary format spec
  │   • Semantic filtering - Vector similarity
  │
  ├── embedder.rs        - Embedder trait + implementations
  ├── fastembed_embedder.rs - ML embedder (MiniLM)
  ├── hash_embedder.rs   - Hash-based fallback
  ├── model_manager.rs   - Model detection/wiring
  └── canonicalize.rs    - Text preprocessing


SUMMARY
───────────────────────────────────────────────────────────────────────────────

CASS achieves sub-10ms interactive search through:

1. Efficient indexing (Tantivy with edge n-grams)
2. Smart caching (prefix + bloom filter gate)
3. Background optimization (warm worker, segment merging)
4. Lazy semantic loading (optional, graceful fallback)
5. Clean post-search filtering (preserves index efficiency)
6. Deterministic RRF fusion (reproducible hybrid ranking)

The architecture balances performance, memory usage, maintainability, and
feature richness - providing a responsive search experience for coding agent
conversation history.

